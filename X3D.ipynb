{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "X3D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1542c0c514064a30a7be46e8e436a723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8f0538512e834346be3b6cbd9924aa8f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_42b313672315478f9b02f60ae35cad53",
              "IPY_MODEL_04174ea18cd74ffe95cd01d3cd8ac5dd",
              "IPY_MODEL_9c53e9901ce442df960312c71360d8d3"
            ]
          }
        },
        "8f0538512e834346be3b6cbd9924aa8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42b313672315478f9b02f60ae35cad53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9db95dae1dc4b0b92bcf180dcbeeec2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_795d16d50d2c4576b721e9223e64aee3"
          }
        },
        "04174ea18cd74ffe95cd01d3cd8ac5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3f89c067519a493e9c7af0d0b4d3df61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 30779313,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 30779313,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e637dd097817430282e7104f0ec1369b"
          }
        },
        "9c53e9901ce442df960312c71360d8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28210c9d6e3d496fa0d33ec0cdedfea5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.4M/29.4M [00:01&lt;00:00, 35.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44a1b7b121044f59aca736987009e8d2"
          }
        },
        "a9db95dae1dc4b0b92bcf180dcbeeec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "795d16d50d2c4576b721e9223e64aee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f89c067519a493e9c7af0d0b4d3df61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e637dd097817430282e7104f0ec1369b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28210c9d6e3d496fa0d33ec0cdedfea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44a1b7b121044f59aca736987009e8d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79131c1ed1e148e29cd282900a683c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a767d01563a54de08279d3be2cf36f7c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab5f1d5520964b7c868ed2a72eeb66c9",
              "IPY_MODEL_12e03cfd2d0842eb8c072c3c73552bd9",
              "IPY_MODEL_44f7eb0a43dd4004ab209c3f381eb030"
            ]
          }
        },
        "a767d01563a54de08279d3be2cf36f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab5f1d5520964b7c868ed2a72eeb66c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d56f7204e6f4451a729e4144e11e292",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b979e9bc05ba4d539177127db3f6a779"
          }
        },
        "12e03cfd2d0842eb8c072c3c73552bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8284fd047ea84f75920f4241faa31544",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 30779313,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 30779313,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1ea798870004d7bb64173ef3cb639de"
          }
        },
        "44f7eb0a43dd4004ab209c3f381eb030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4a1cc7a63224b46a9cb0b5bd2a6acf1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.4M/29.4M [00:01&lt;00:00, 23.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2e145c5b62944d0b72577d1cfdc17a8"
          }
        },
        "1d56f7204e6f4451a729e4144e11e292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b979e9bc05ba4d539177127db3f6a779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8284fd047ea84f75920f4241faa31544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1ea798870004d7bb64173ef3cb639de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4a1cc7a63224b46a9cb0b5bd2a6acf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2e145c5b62944d0b72577d1cfdc17a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liu-feng116/EvaluateModels/blob/main/X3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6cE32bSjBeU"
      },
      "source": [
        "1.import模块"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAMWjnoZ_f8R"
      },
      "source": [
        "try:\n",
        "    import torch\n",
        "except ModuleNotFoundError:\n",
        "    !pip install torch torchvision\n",
        "    import os\n",
        "    import sys\n",
        "    import torch\n",
        "    \n",
        "if torch.__version__=='1.6.0+cu101' and sys.platform.startswith('linux'):\n",
        "    !pip install pytorchvideo\n",
        "else:\n",
        "    need_pytorchvideo=False\n",
        "    try:\n",
        "        # Running notebook locally\n",
        "        import pytorchvideo\n",
        "    except ModuleNotFoundError:\n",
        "        need_pytorchvideo=True\n",
        "    if need_pytorchvideo:\n",
        "        # Install from GitHub\n",
        "        !pip install \"git+https://github.com/facebookresearch/pytorchvideo.git\"\n",
        "\n",
        "import json \n",
        "from torchvision.transforms import Compose, Lambda\n",
        "from torchvision.transforms._transforms_video import (\n",
        "    CenterCropVideo,\n",
        "    NormalizeVideo,\n",
        ")\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        "    UniformCropVideo\n",
        ") \n",
        "from typing import Dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc6a6wjcjWLK"
      },
      "source": [
        "2.下载测试数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZs6M86NjZRF",
        "outputId": "b04c8644-1d17-4f87-9f2b-5540f18aadc0"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json\n",
        "with open(\"kinetics_classnames.json\", \"r\") as f:\n",
        "    kinetics_classnames = json.load(f)\n",
        "\n",
        "# 对数据集标签进行处理\n",
        "kinetics_id_to_classname = {}\n",
        "for k, v in kinetics_classnames.items():\n",
        "    kinetics_id_to_classname[v] = str(k).replace('\"', \"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-07 16:04:57--  https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10326 (10K) [text/plain]\n",
            "Saving to: ‘kinetics_classnames.json.2’\n",
            "\n",
            "kinetics_classnames 100%[===================>]  10.08K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-07 16:04:57 (53.2 MB/s) - ‘kinetics_classnames.json.2’ saved [10326/10326]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbeSl4x_kA0z"
      },
      "source": [
        "3.利用Torch Hub加载预处理模型，这里选择根据tutorial先测试slowfast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qromrhr5kSHP"
      },
      "source": [
        "def get_model(device, model_name):\n",
        "  # 从torch hub导入model\n",
        "  model = torch.hub.load(\"facebookresearch/pytorchvideo:main\", model=model_name, pretrained=True)\n",
        "  # 设置eval（测试），设置设备\n",
        "  model = model.to(device)\n",
        "  model = model.eval()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naglW4njmn3Z"
      },
      "source": [
        "4.加载example video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRWrTPh2muUl",
        "outputId": "a85db559-1f9f-4377-cfe6-e67186ac1ed7"
      },
      "source": [
        "# 下载example video\n",
        "!wget https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-07 16:04:57--  https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 549197 (536K) [video/mp4]\n",
            "Saving to: ‘archery.mp4.1’\n",
            "\n",
            "archery.mp4.1       100%[===================>] 536.33K  2.13MB/s    in 0.2s    \n",
            "\n",
            "2021-11-07 16:04:58 (2.13 MB/s) - ‘archery.mp4.1’ saved [549197/549197]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e6ldULlIiCT"
      },
      "source": [
        "5.设置输入变换（input transformation）并对视频切片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OedL1H7tm3Kg"
      },
      "source": [
        "def clip(video_path, start_sec, device, model_name):\n",
        "  # 设置输入变换（input transformation）\n",
        "  mean = [0.45, 0.45, 0.45]\n",
        "  std = [0.225, 0.225, 0.225]\n",
        "  frames_per_second = 30\n",
        "  model_transform_params  = {\n",
        "      \"x3d_xs\": {\n",
        "          \"side_size\": 182,\n",
        "          \"crop_size\": 182,\n",
        "          \"num_frames\": 4,\n",
        "          \"sampling_rate\": 12,\n",
        "      },\n",
        "      \"x3d_s\": {\n",
        "          \"side_size\": 182,\n",
        "          \"crop_size\": 182,\n",
        "          \"num_frames\": 13,\n",
        "          \"sampling_rate\": 6,\n",
        "      },\n",
        "      \"x3d_m\": {\n",
        "          \"side_size\": 256,\n",
        "          \"crop_size\": 256,\n",
        "          \"num_frames\": 16,\n",
        "          \"sampling_rate\": 5,\n",
        "      }\n",
        "  }\n",
        "\n",
        "  # Get transform parameters based on model\n",
        "  transform_params = model_transform_params[model_name]\n",
        "\n",
        "  # Note that this transform is specific to the slow_R50 model.\n",
        "  transform =  ApplyTransformToKey(\n",
        "      key=\"video\",\n",
        "      transform=Compose(\n",
        "          [\n",
        "              UniformTemporalSubsample(transform_params[\"num_frames\"]),\n",
        "              Lambda(lambda x: x/255.0),\n",
        "              NormalizeVideo(mean, std),\n",
        "              ShortSideScale(size=transform_params[\"side_size\"]),\n",
        "              CenterCropVideo(\n",
        "                  crop_size=(transform_params[\"crop_size\"], transform_params[\"crop_size\"])\n",
        "              )\n",
        "          ]\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  # The duration of the input clip is also specific to the model.\n",
        "  clip_duration = (transform_params[\"num_frames\"] * transform_params[\"sampling_rate\"])/frames_per_second\n",
        "\n",
        "  # 对视频进行切片处理\n",
        "  # 选择要加载的切片的持续时间。\n",
        "  end_sec = start_sec + clip_duration \n",
        "  # 初始化EncodeVideo类\n",
        "  video = EncodedVideo.from_path(video_path)\n",
        "  # 加载所需的切片数据\n",
        "  video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
        "  # 应用此前设置的输入变换处理切片数据\n",
        "  video_data = transform(video_data)\n",
        "  # 将切片数据加载到cpu内存\n",
        "  inputs = video_data[\"video\"]\n",
        "  inputs = inputs.to(device)\n",
        "  return inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmJQpN1vpyaG"
      },
      "source": [
        "6.进行prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMqlw_I4p84a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1542c0c514064a30a7be46e8e436a723",
            "8f0538512e834346be3b6cbd9924aa8f",
            "42b313672315478f9b02f60ae35cad53",
            "04174ea18cd74ffe95cd01d3cd8ac5dd",
            "9c53e9901ce442df960312c71360d8d3",
            "a9db95dae1dc4b0b92bcf180dcbeeec2",
            "795d16d50d2c4576b721e9223e64aee3",
            "3f89c067519a493e9c7af0d0b4d3df61",
            "e637dd097817430282e7104f0ec1369b",
            "28210c9d6e3d496fa0d33ec0cdedfea5",
            "44a1b7b121044f59aca736987009e8d2",
            "79131c1ed1e148e29cd282900a683c10",
            "a767d01563a54de08279d3be2cf36f7c",
            "ab5f1d5520964b7c868ed2a72eeb66c9",
            "12e03cfd2d0842eb8c072c3c73552bd9",
            "44f7eb0a43dd4004ab209c3f381eb030",
            "1d56f7204e6f4451a729e4144e11e292",
            "b979e9bc05ba4d539177127db3f6a779",
            "8284fd047ea84f75920f4241faa31544",
            "c1ea798870004d7bb64173ef3cb639de",
            "f4a1cc7a63224b46a9cb0b5bd2a6acf1",
            "f2e145c5b62944d0b72577d1cfdc17a8"
          ]
        },
        "outputId": "288ce4f6-9ea0-4f31-a423-8566ed9158d2"
      },
      "source": [
        "import time\n",
        "time_list = []\n",
        "mean_time = 0.0\n",
        "model_list = [\"x3d_xs\", \"x3d_s\", \"x3d_m\"]\n",
        "for model_name in model_list:\n",
        "  print(\"-----------------------\")\n",
        "  print(\"The model of %s is running:\" % model_name)\n",
        "  # 开始预测\n",
        "  for i in range(10):\n",
        "    # 向model导入切片数据\n",
        "    inputs = clip(\"archery.mp4\", 0, \"cpu\", model_name)\n",
        "    model = get_model(\"cpu\", model_name)\n",
        "\n",
        "    # 开始计时\n",
        "    start = time.clock()\n",
        "\n",
        "    preds = model(inputs[None, ...])\n",
        "\n",
        "    # 结束计时\n",
        "    end = time.clock()\n",
        "\n",
        "    # 累计求和\n",
        "    mean_time = mean_time + (end - start)\n",
        "\n",
        "    # 获得预测类别\n",
        "    post_act = torch.nn.Softmax(dim=1)\n",
        "    preds = post_act(preds)\n",
        "    pred_classes = preds.topk(k=5).indices\n",
        "    print(pred_classes)\n",
        "\n",
        "    # 通过kineticss_id_to_classname获取对应indices的label\n",
        "    pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_classes[0]]\n",
        "    print(\"%d round:\" % i )\n",
        "    print(\"Predicted labels: %s\" % \", \".join(pred_class_names))\n",
        "  \n",
        "  # 平均\n",
        "  mean_time = mean_time/10\n",
        "  time_list.append(mean_time)\n",
        "  print('time: %e' % mean_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "The model of x3d_xs is running:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5, 142, 141, 356,   3]])\n",
            "0 round:\n",
            "Predicted labels: archery, golf driving, golf chipping, throwing axe, applauding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5, 142, 141, 356,   3]])\n",
            "1 round:\n",
            "Predicted labels: archery, golf driving, golf chipping, throwing axe, applauding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5, 142, 141, 356,   3]])\n",
            "2 round:\n",
            "Predicted labels: archery, golf driving, golf chipping, throwing axe, applauding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5, 142, 141, 356,   3]])\n",
            "3 round:\n",
            "Predicted labels: archery, golf driving, golf chipping, throwing axe, applauding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5, 142, 141, 356,   3]])\n",
            "4 round:\n",
            "Predicted labels: archery, golf driving, golf chipping, throwing axe, applauding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5, 142, 141, 356,   3]])\n",
            "5 round:\n",
            "Predicted labels: archery, golf driving, golf chipping, throwing axe, applauding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5, 142, 141, 356,   3]])\n",
            "6 round:\n",
            "Predicted labels: archery, golf driving, golf chipping, throwing axe, applauding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5, 142, 141, 356,   3]])\n",
            "7 round:\n",
            "Predicted labels: archery, golf driving, golf chipping, throwing axe, applauding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5, 142, 141, 356,   3]])\n",
            "8 round:\n",
            "Predicted labels: archery, golf driving, golf chipping, throwing axe, applauding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5, 142, 141, 356,   3]])\n",
            "9 round:\n",
            "Predicted labels: archery, golf driving, golf chipping, throwing axe, applauding\n",
            "time: 4.000915e-01\n",
            "-----------------------\n",
            "The model of x3d_s is running:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/X3D_S.pyth\" to /root/.cache/torch/hub/checkpoints/X3D_S.pyth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1542c0c514064a30a7be46e8e436a723",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/29.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "0 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "1 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "2 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "3 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "4 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "5 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "6 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "7 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "8 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "9 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n",
            "time: 1.283508e+00\n",
            "-----------------------\n",
            "The model of x3d_m is running:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/X3D_M.pyth\" to /root/.cache/torch/hub/checkpoints/X3D_M.pyth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79131c1ed1e148e29cd282900a683c10",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/29.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "0 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "1 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "2 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "3 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "4 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "5 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "6 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "7 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "8 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 1, 3, 4, 0]])\n",
            "9 round:\n",
            "Predicted labels: archery, air drumming, applauding, applying cream, abseiling\n",
            "time: 3.116712e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g5j6cwO6gn3"
      },
      "source": [
        "7.绘制图像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "dg41xsrI6mPF",
        "outputId": "1f0f1944-3ecd-4be8-c310-7ffdb8ffb5c8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.bar(model_list, time_list, width=0.2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}